{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb5e1fd-a14a-417a-b9ff-95763fd3702a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2727b6f5-a7a8-430e-bf6c-04711d2d6614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1449073579402538#setting/sparkui/1025-024307-3l0j2773/driver-6482606874410438979\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8bfa200090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953f1abf-963b-4410-a439-6d1f1cde1438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark configs to access Azure Storage Account :  generate SAS key in Storage Account and assign it in spark session\n",
    "\n",
    "sas_token = \"sv=2022-11-02&ss=bfqt&srt=c&sp=rwdytfx&se=2024-10-25T22:33:32Z&st=2024-10-25T14:33:32Z&spr=https&sig=eSSfv95GHRHT6WSwaXqGJwLxjvCifpg9k7ydlEMIqIY%3D\"  \n",
    "\n",
    "storage_account_key = \"vAh0MYzXTTOUynsGtdwk6AFZT+0dNPazQiueINdLM2hyZY+cjJQNMmaawILe0DSKB01YmGf85Ma1+AStxBfsqw==\"\n",
    "\n",
    "storage_account = \"myfirstblobstoragesample\"\n",
    "container_name = \"databrickssample\"\n",
    "file_name = \"sales_data.csv\"\n",
    "\n",
    "csv_file_url = f\"wasbs://{container_name}@{storage_account}.blob.core.windows.net/{file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ae53121-411c-4656-9a03-97a6f835f306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test connection to Blob Storage\n",
    "dbutils.fs.ls(f\"wasbs://{container_name}@{storage_account}.blob.core.windows.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4630f0c0-98b8-4be7-9a9e-72b4816a8da5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up the Spark configuration for SAS token\n",
    "spark.conf.set( f\"fs.azure.sas.{storage_account}.blob.core.windows.net\", \n",
    "               sas_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf17842b-2800-4e73-9540-1734f76d2cd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up the Spark configuration for Azure Blob Storage\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account}.blob.core.windows.net\",\n",
    "    storage_account_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feb2ad88-abb9-4122-a028-ef95542c2169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csvDF = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(csv_file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aeec7d6-6c23-4e93-8c46-9886dee42d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+----------+--------+--------------+-----------+-------+\n|transaction_id|      date|customer_id|product_id|quantity|price_per_unit|total_price|country|\n+--------------+----------+-----------+----------+--------+--------------+-----------+-------+\n|          1001|2024-01-01|       C001|      P001|       2|            20|         40|    USA|\n|          1002|2024-01-02|       C002|      P002|       1|            50|         50| Canada|\n|          1003|2024-01-03|       C003|      P001|       3|            20|         60|    USA|\n|          1004|2024-01-04|       C001|      P003|       4|            10|         40| Mexico|\n|          1005|2024-01-05|       C004|      P002|       2|            50|        100| Canada|\n|          1006|2024-01-06|       C005|      P003|       1|            10|         10|    USA|\n|          1007|2024-01-07|       C006|      P001|       5|            20|        100|    USA|\n|          1008|2024-01-08|       C007|      P002|       3|            50|        150| Canada|\n|          1009|2024-01-09|       C008|      P003|       2|            10|         20| Mexico|\n|          1010|2024-01-10|       C009|      P001|       4|            20|         80|    USA|\n+--------------+----------+-----------+----------+--------+--------------+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "csvDF.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sales_EDA_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}